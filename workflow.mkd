# Log into uppmax
ssh [username]@rackham.uppmax.uu.se

# Pull the data

## Create softlinks of bam files to personal working directory
```bash
# Move to working/parent directory
cd /proj/sparrowhybridization/Pitaliae/working/Arianna

mkdir Data # make a new directory within the parent directory
cd Data # move into Data

# Create a softink to the bamfiles within the Data directory
ln -s /proj/sparrowhybridization/Pitaliae/data/WGS/bamfiles/ Bamfiles
```

## Download the new house sparrow reference genome from NCBI (accession: GCA_036417665.1)
```bash
# In the Data directory
mkdir ReferenceGenome
cd ReferenceGenome

# Command line download unsuccessful, download to local computer then move to uppmax server: https://www.ncbi.nlm.nih.gov/datasets/genome/GCA_036417665.1/
scp ncbi_dataset.zip [username]@rackham.uppmax.uu.se:/proj/sparrowhybridization/Pitaliae/working/Arianna/Data/ReferenceGenome

# Investigate headers
cat GCA_036417665.1_bPasDom1.hap1_genomic.fna | grep \>
```

# Get basic alignment stats for existing BAM files using SAMtools flagstat (v1.12)
```bash
# Move back to personal working directory
cd ../../

# Create a new directory
mkdir 01_FlagstatExistingBAM
cd 01_FlagstatExistingBAM

# Start an interactive environment
interactive -A naiss2023-5-262 -n 16 -t 1:00:00 # should take ~45 minutes

module load bioinfo-tools
module load samtools/1.14

# Run samtools on each bam file
for dir in ../Data/Bamfiles/*/; do # ${dir} contains entire path

    dirName=$(basename "$dir") # just the name of the specific directory is stored (e.g corsica)

    outputDir="${dirName}_flagstats" # store a directory name (e.g. corsica_flagstats)

    mkdir "$outputDir" # make a directory of this name in the current directory, 01_FlagstatsExistingBAM

    for bam in ${dir}/*.bam; do # for each file in the directory that ends in .bam

        file=$(basename "$bam" .bam); # pull the basename, e.g. "K032_resorted_nodup_realigned"

        if [[ "$file" == Rimini* || "$file" == Lesina* ]]; # Rimini and Lesina populations follow a different format
        then
            prefix=${file} # pull the basename, e.g. "Rimini_112"
        else
            prefix=$(basename "$bam" .bam | cut -d "_" -f 1) # for all other populations, pull the basename "K032_resorted_nodup_realigned" then just "K032"
        fi

        samtools flagstat "${bam}" -@ 16 > "${outputDir}/${prefix}.flagstat" # run w/16 threads on each .bam file, save (e.g. "K032.flagstat") to corresponding directory

    done
done
```

Outputs: 1 output per .bam file for each population. Outputs are named [id].flagstat and housed within a subdirectory of 01_FlagstatExistingBAM named [population]_flagstats

# Re-map BAM files to new House Sparrow Reference Genome using SAMtools (v1.12)

## Create a directory for remapping task
```bash
# Move to working/parent directory
cd /proj/sparrowhybridization/Pitaliae/working/Arianna

mkdir 02_Remap # create a new subdirectory
```

## Index the new reference genome with BWA (v0.7.17)
```bash
# When attempting to run Heng Li's code on remapping an aligned BAM, received this error: [E::bwa_idx_load_from_disk] fail to locate the index files
# To resolve, index the new reference genome

interactive -A naiss2023-5-262 -n 12 -t 0:45:00 # request an interactive environment

module load bioinfo-tools
module load samtools/1.12 # latest version at the time of Heng Li's post
module load bwa/0.7.17 #latest version at the time of Heng Li's post

# Move to directory that houses the new reference genome
cd Data/ReferenceGenome

# Prior to remapping, run bwa index
bwa index GCA_036417665.1_bPasDom1.hap1_genomic.fna # should take ~ 45 minutes
```

Ouputs: 5 files with a basename of GCA_036417665.1_bPasDom1.hap1_genomic.fna (the file name of the reference genome)

(1) [basename].amb (2) [basename].ann (3)[basename].bwt (4) [basename].pac (5) [basename].sa

## Create a folder to house project scripts & create scripts
```bash
cd /proj/sparrowhybridization/Pitaliae/working/Arianna

mkdir Scripts
cd Scripts

mkdir 02_Remap_scripts
cd 02_Remap_scripts # scripts for this task should be located here!
```

There should be 12 scripts in this folder! Each script will remap the bam files for a population (population specified in script name). Originally wrote one script to remap all the bam files for every population,but it would take many days to run this script on one node. Therefore, we will run 1 job per population instead of 1 job for all the bam files!

### Example code for remapping just one BAM file
```bash
interactive -A naiss2023-5-262 -n 20 -t 2:00:00

module load bioinfo-tools
module load samtools/1.12 # latest version at the time of Heng Li's post
module load bwa/0.7.17 # latest version at the time of Heng Li's post

# Code pulled from Heng Li's blogpost, see link for command-by-command description
# https://lh3.github.io/2021/07/06/remapping-an-aligned-bam
# 20 cores per node, 1 thread per core! Specify 20 threads for each task
samtools collate -Oun128 ../Data/Bamfiles/corsica/K006_resorted_nodup_realigned.bam -@ 20 | samtools fastq -OT RG,BC -@ 20 - \
| bwa mem -pt8 -CH <(samtools view -H ../Data/Bamfiles/corsica/K006_resorted_nodup_realigned.bam|grep ^@RG) ../Data/ReferenceGenome/GCA_036417665.1_bPasDom1.hap1_genomic.fna -t 20 - \
| samtools sort -@ 20 -m4g -o K006_remapped.bam -
```

## Create jobs for each remapping script
```bash
# Corsica, batch job 46179245
sbatch -A naiss2023-5-262 -p node -t 17:30:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/02_Remap -e ../Job_logs/02_Remap_logs/remapping_corsica.err -J remap_existingBAM_corsica --mail-user=ar4666al-s@student.lu.se --mail-type=ALL remap_corsica.sh

# Crete, batch job 46179242
sbatch -A naiss2023-5-262 -p node -t 7:30:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/02_Remap -e ../Job_logs/02_Remap_logs/remapping_crete.err -J remap_existingBAM_crete --mail-user=ar4666al-s@student.lu.se --mail-type=ALL remap_crete.sh

# Crotone, batch job 46179247
sbatch -A naiss2023-5-262 -p node -t 10:30:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/02_Remap -e ../Job_logs/02_Remap_logs/remapping_crotone.err -J remap_existingBAM_crotone --mail-user=ar4666al-s@student.lu.se --mail-type=ALL remap_crotone.sh

# Guglionesi, batch job 46179248
sbatch -A naiss2023-5-262 -p node -t 12:00:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/02_Remap -e ../Job_logs/02_Remap_logs/remapping_guglionesi.err -J remap_existingBAM_guglionesi --mail-user=ar4666al-s@student.lu.se --mail-type=ALL remap_guglionesi.sh

# House, batch job 46220281
sbatch -A naiss2023-5-262 -p node -t 15:30:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/02_Remap -e ../Job_logs/02_Remap_logs/remapping_house.err -J remap_existingBAM_house --mail-user=ar4666al-s@student.lu.se --mail-type=ALL remap_house.sh

# Malta, batch job 46179250
sbatch -A naiss2023-5-262 -p node -t 13:30:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/02_Remap -e ../Job_logs/02_Remap_logs/remapping_malta.err -J remap_existingBAM_malta --mail-user=ar4666al-s@student.lu.se --mail-type=ALL remap_malta.sh

# Miscellaneous, batch job 46220282
sbatch -A naiss2023-5-262 -p node -t 13:30:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/02_Remap -e ../Job_logs/02_Remap_logs/remapping_miscellaneous.err -J remap_existingBAM_miscellaneous --mail-user=ar4666al-s@student.lu.se --mail-type=ALL remap_miscellaneous.sh

# P_montanus, batch job 46220283
sbatch -A naiss2023-5-262 -p node -t 13:30:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/02_Remap -e ../Job_logs/02_Remap_logs/remapping_p_montanus.err -J remap_existingBAM_p_montanus --mail-user=ar4666al-s@student.lu.se --mail-type=ALL remap_p_montanus.sh

# Rimini, batch job 46179255
sbatch -A naiss2023-5-262 -p node -t 9:30:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/02_Remap -e ../Job_logs/02_Remap_logs/remapping_rimini.err -J remap_existingBAM_rimini --mail-user=ar4666al-s@student.lu.se --mail-type=ALL remap_rimini.sh

# Sardinia, batch job 46179256
sbatch -A naiss2023-5-262 -p node -t 10:30:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/02_Remap -e ../Job_logs/02_Remap_logs/remapping_sardinia.err -J remap_existingBAM_sardinia --mail-user=ar4666al-s@student.lu.se --mail-type=ALL remap_sardinia.sh

# Sicily, batch job 46179347
sbatch -A naiss2023-5-262 -p node -t 9:30:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/02_Remap -e ../Job_logs/02_Remap_logs/remapping_sicily.err -J remap_existingBAM_sicily --mail-user=ar4666al-s@student.lu.se --mail-type=ALL remap_sicily.sh

# Spanish, batch job 46179498
sbatch -A naiss2023-5-262 -p node -t 14:30:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/02_Remap -e ../Job_logs/02_Remap_logs/remapping_spanish.err -J remap_existingBAM_spanish --mail-user=ar4666al-s@student.lu.se --mail-type=ALL remap_spanish.sh
```

## Index the new BAM files using SAMtools (v1.12)
```bash
# Create a script (index_remapped.sh) to index the bam files and save it to Arianna/Scripts/02_Remap_scripts

# Move into the Arianna/Scripts/02_Remap_scripts directory
cd /proj/sparrowhybridization/Pitaliae/working/Arianna/Scripts/02_Remap_scripts

# Indexing, batch job 46239392
sbatch -A naiss2023-5-262 -p core -n 16 -t 1:00:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna -e Job_logs/02_Remap_logs/indexing.err -J indexing_remapped_BAM --mail-user=ar4666al-s@student.lu.se --mail-type=ALL index_remapped.sh
```
Outputs: 1 output per bam file. Outputs are named [id]_remapped.bam.bai and housed in the same directory as the corresponding bam files

# Run SAMtools (v1.14) flagstat on the new BAM files
```bash
# Create a new directory to store flagstat output of task
cd ../.. # back to Arianna working directory
mkdir 03_FlagstatRemappedBAM

# Move to Scripts directory
cd Scripts

# Create a scripts directtory for the task, create flagstat_remapped.sh script and store it here
mkdir 03_FlagstatRemappedBAM_scripts
cd 03_FlagstatRemappedBAM_scripts

# Flagstats on remapped bam files, batch job 46240169
sbatch -A naiss2023-5-262 -p core -n 16 -t 1:30:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/03_FlagstatRemappedBAM -e ../Job_logs/03_FlagstatRemappedBAM_logs/flagstat.err -J flagstat_remapped_BAM --mail-user=ar4666al-s@student.lu.se --mail-type=ALL flagstat_remapped.sh
```
Outputs: 1 output per .bam file for each population. Outputs are named [id]_remapped.flagstat and housed within a subdirectory of 03_FlagstatRemappedBAM named [population]_remap_flagstats

# Merge samtools flagstat output for each existing and remapped bam
``` bash
# Create a new directory to store merged flagstat files
cd ../.. # back to Arianna working directory
mkdir 04_FlagstatCombined
cd 04_FlagstatCombined

# Combine the flagstat files
for dir_existing in ../01_FlagstatExistingBAM/*/; do # ${dir_existing} contains entire path

    dir_existingName=$(basename "$dir_existing") # just the name of the specific directory is stored (e.g corsica_flagstats)

    outputDir="${dir_existingName}_combined" # store a directory name (e.g. corsica_flagstats_combined)

    mkdir "$outputDir" # make a directory of this name in the current directory, 04_FlagstatCombined

    for dir_remapped in ../03_FlagstatRemappedBAM/*/; do

        for flagstat_existing in ${dir_existing}/*.flagstat; do # for the existing bam flagstat files

            prefix_existing=$(basename "$flagstat_existing" .flagstat) # pull just K032 instead of K032.flagstat
            
            for flagstat_remapped in ${dir_remapped}/*.flagstat; do # for the remapped bam flagstat files

                prefix_remapped=$(basename "$flagstat_remapped" "_remapped.flagstat") # pull just Rimini_91 from Rimini_91_remapped.flagstat


                if [[ "$prefix_existing" == "$prefix_remapped" ]]; # if the prefixes for existing and remapped match (e.g. Rimini_91 == Rimini_91)
                then
                    echo -e ">\n>${prefix_existing}.bam flagstat output (existing bam file)" > tempHeader_exisiting # create a temporary header for the existing flagstat output, overwrite for each iteration

                    echo -e ">\n>${prefix_remapped}_remapped.bam flagstat output (remapped bam file)" > tempHeader_remapped # create a temporary header for the remapped flagstat output, overwrite for each iteration

                    cat tempHeader_exisiting ${flagstat_existing} tempHeader_remapped ${flagstat_remapped} > "${outputDir}/${prefix_existing}_combo.flagstat" # vertically concatenate the existing header + existing flagstat output + remapped header + remapped flagstat output
                else
                    continue # if the prefixes don't match, don't do anything
                fi

            done

        done
        
    done
done
```
Outputs: 1 output per sample file for each population. Outputs are named [id]_combo.flagstat and housed within a subdirectory of 04_FlagstatCombined named [population]_flagstats_combined

# Variant Calling

## Add prefix to Malta miscellaneous samples
```bash
# There are different files with the same sample name in the malta_remap folder and miscellaneous_remap
# bcftools will only include one file if another is a duplicate (regardless of changing file names, scans contents of file to determine)

# add "misc" prefix to the "M" samples in the miscellaneous folder
# to differentiate between the two duplicate sample IDs and check vcf header to be sure the samples from malta_remap were used to call variants

cd ../02_Remap/miscellaneous_remap/ # move to directory containing remapped miscellaneous bam files

for bam in M*; do # for files in this directory that start with "M"

    # Append "misc" to the start of the file name
    newName="misc_$bam" 

    # Rename the file
    mv "$bam" "$newName" # e.g. misc_M019_remapped.bam
done

# Since we know that 2 samples won't be inlcuded, we know that 124 samples will actually be included in the VCF! Still call the files 126 sample vcf for now
```

## Generate all site BCFs using BCFtools (v 1.14)
```bash
# Move to home working directory
cd /proj/sparrowhybridization/Pitaliae/working/Arianna

# Create a subdirectory for the task
mkdir 05_AllSiteBCFs
cd 05_AllSiteBCFs

# Create a file which lists the path to every bam file on a new line
for dir in ../02_Remap/*_remap/; do # ${dir} contains entire path

    for bam in ${dir}/*.bam; do # stores the path to each file that ends in .bam to ${bam}

        echo ${bam} >> mappedReads_paths # Will create the file and append the path stored in ${bam} for each iteration

    done
done

# Create a file with the names of all the chromosomes present in the reference, .fai is the index file!
cat ../Data/ReferenceGenome/GCA_036417665.1_bPasDom1.hap1_genomic.fna.fai | cut -f 1 >> chromo_list # "chromosomes" based on fna header so e.g. CM071426.1 = chromosome 1

# Move to the Scripts directory
cd ../Scripts/

# Create a subdirectory
mkdir 05_AllSiteBCFs_scripts
cd 05_AllSiteBCFs_scipts

# Modify Kalle's script called bcftools.sh (& turn it into an array job) and move it into this directory. Now called bcftools_array.sh

# Submit the array job to call variants for each chromosome & scaffold separateley, batch job 46316581
sbatch -A naiss2023-5-262 --array=1-334 --ntasks=1 -t 4-00:00:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/05_AllSiteBCFs -e ../Job_logs/05_AllSiteBCFs_logs/126samples_bcf.err -J 126samples_bcf --mail-user=ar4666al-s@student.lu.se --mail-type=ALL bcftools_array.sh
```
Outputs: 1 output BCF file per region (chromosome/scaffold), 334 BCF files total. Outputs are named 126sample_v_gc_raw_[regionID].bcf and are located in the 05_AllSiteBCFs directory

## Generate BCFs with just biallelic sites using BCFtools (v 1.14)
```bash
# Move to home working directory
cd /proj/sparrowhybridization/Pitaliae/working/Arianna

# Create a subdirectory for the task
mkdir 06_BiallelicSiteBCFs
cd 06_BiallelicSiteBCFs

# Create a file with the paths to each all-site bcf file
for bcf in ../05_AllSiteBCFs/*.bcf; do # ${bcf} contains entire path

    echo ${bcf} >> bcf_paths # Will create the file and append the path stored in ${bcf} for each iteration

done

# Move to the Scripts directory
cd ../Scripts

# Create a subdirectory
mkdir 06_BiallelicSiteBCFs_scripts
cd 06_BiallelicSiteBCFs_scripts

# Make a script called bcftools_biallelic.sh to just pull the biallelic site for each of of the bcf files

# Submit job to pull just biallelic variants for each bcf, batch job 46440834
sbatch -A naiss2023-5-262 --array=1-334 --ntasks=20 -t 2:00:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/06_BiallelicSiteBCFs -e ../Job_logs/06_BiallelicSiteBCFs_logs/biallelic_bcfs.err -J biallelic_bcfs --mail-user=ar4666al-s@student.lu.se --mail-type=ALL bcftools_biallelic.sh
```
Outputs: 1 output BCF file per region (chromosome/scaffold), 334 BCF files total. Outputs are named 126sample_[regionID]_biallelicSites.bcf and are located in the 06_BiallelicSiteBCFs directory

# Determine filtering thresholds

## Randomly sample ~100,000 calls (of biallelic sites) to determine filtering thresholds, following workflow from https://speciationgenomics.github.io/filtering_vcfs/
```bash
# Move back to home working directory
cd /proj/sparrowhybridization/Pitaliae/working/Arianna

# Create a subdirectory called
mkdir 07_PreFiltering
cd 07_PreFiltering

# Create a file with the paths to each bcf (biallelic sites only)
for bcf in ../06_BiallelicSiteBCFs/*.bcf; do # ${bcf} contains entire path

    echo ${bcf} >> biallelic_bcf_paths # Will create the file and append the path stored in ${bcf} for each iteration

done

# Move to the Scripts directory
cd ../Scripts

# Create a subdirectory
mkdir 07_PreFiltering_scripts
cd 07_PreFiltering_scripts

# Make a script called countCallsBCF.sh to count the number of calls in each bcf and append that number to a list called countCallsList

# Submit array job to count calls for each bcf (biallelic calls only), batch job 46441607
sbatch -A naiss2023-5-262 --array=1-334 --ntasks=1 -t 1:00:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/07_PreFiltering -e ../Job_logs/07_PreFiltering_logs/countCalls.err -J countCalls --mail-user=ar4666al-s@student.lu.se --mail-type=ALL countCallsBCF.sh

# Use awk to count all the numbers in the file
cd ../../07_PreFiltering/
awk '{sum+=$1} END {print sum}' countCallsList # 66,887,744 calls -> multuply by 0.00145 = ~ 100,000 calls
```

```bash
# Randomly pull sites from each BCF (only biallelic sites) to equal ~100,000 sites and then concatenate, will take approx 2 hours. Alternatively, could have randomly pull ~100,000 calls from a concatenated bcf (biallelic sites only), but would take 20+ hours

# Move to scripts directory
cd ../Scripts/07_PreFiltering_scripts

# Make a script called pullSubsets.sh to randomly pull sites from each BCF (biallelic) totalling to ~100,000 calls
# Submit array job, batch job 46443715
sbatch -A naiss2023-5-262 --array=1-334 --ntasks=1 -t 5:00:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/07_PreFiltering -e ../Job_logs/07_PreFiltering_logs/pullSubsets.err -J pullSubsets --mail-user=ar4666al-s@student.lu.se --mail-type=ALL pullSubsets.sh
```
Outputs, option 1: 1 output VCF file per region (chromosome/scaffold), 334 BCF files total. Outputs are named 126sample_[regionID]_biallelicSites_subset.vcf and are located in the 07_PreFiltering directory

```bash
# Move to scripts directory if not already there
cd /proj/sparrowhybridization/Pitaliae/working/Arianna/Scripts/07_PreFiltering_scripts

# Create a script called concatSubsetVCFs.sh to concatenate the subset VCFs into one VCF
# Submit job, batch job 46444847
sbatch -A naiss2023-5-262 -p node -t 1:00:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/07_PreFiltering -e ../Job_logs/07_PreFiltering_logs/concat_subsets.err -J concat_subsets --mail-user=ar4666al-s@student.lu.se --mail-type=ALL concatSubsetVCFs.sh
```
Output: 1 output, compressed VCF file called sparrow_biallelics_subset.vcf.gz located in the 07_PreFiltering directory

```bash
# To make the 07_PreFiltering directory easier to navigate, move the individidual subset files to their own directory
cd /proj/sparrowhybridization/Pitaliae/working/Arianna/07_PreFiltering
mkdir Subsets
mv *biallelicSites_subset.vcf ./Subsets
```

```bash
# Move to 07_PreFiltering directory if not already there
cd /proj/sparrowhybridization/Pitaliae/working/Arianna/07_PreFiltering

# Start an interactive environment
interactive -A naiss2023-5-262 -n 20 -t 1:00:00
module load bioinfo-tools
module load bcftools/1.14

# Concatenate autosomes and scaffold subsets into one vcf
for vcf in ./Subsets/*biallelicSites_subset.vcf; do # ${vcf} contains entire path

    prefix=$(basename "$vcf" .vcf)

    if [[ "$prefix" == *CM071456.1* || "$prefix" == *CM071464.1* ]]; # if Z chrom (CM071456.1) or W chrom (CM071464.1)
    then
        continue
    else
        echo ${vcf} >> VCFsubset_paths_autosomal
    fi
done

bcftools concat --threads 20 --file-list VCFsubset_paths_autosomal -Oz -o sparrow_biallelics_subset_AUTOSOMES.vcf.gz

# Concatenate the sex chromosome subsets
for vcf in ./Subsets/*biallelicSites_subset.vcf; do # ${vcf} contains entire path

    prefix=$(basename "$vcf" .vcf)

    if [[ "$prefix" == *CM071456.1* || "$prefix" == *CM071464.1* ]]; # if Z chrom (CM071456.1) or W chrom (CM071464.1)
    then
        echo ${vcf} >> VCFsubset_paths_sex
    else
        continue
    fi
done

bcftools concat --threads 20 --file-list VCFsubset_paths_sex -Oz -o sparrow_biallelics_subset_SEX.vcf.gz

# Create compressed VCFs for the individual sex chromosome subsets
bcftools view ./Subsets/126sample_CM071456.1_biallelicSites_subset.vcf -Oz -o sparrow_biallelics_subset_zChrom.vcf.gz
bcftools view ./Subsets/126sample_CM071464.1_biallelicSites_subset.vcf -Oz -o sparrow_biallelics_subset_wChrom.vcf.gz
```
Output: 4 compressed VCF files, named as shown above, located in the 07_PreFiltering directory

```bash
# index the compressed VCFs
bcftools index sparrow_biallelics_subset.vcf.gz
bcftools index sparrow_biallelics_subset_AUTOSOMES.vcf.gz
bcftools index sparrow_biallelics_subset_SEX.vcf.gz
bcftools index sparrow_biallelics_subset_zChrom.vcf.gz
bcftools index sparrow_biallelics_subset_wChrom.vcf.gz
```
Output: 5 output files that follow this format: [inputFileName].csi, located in the 07_PreFiltering directory 

## Generate stats for the concatenated subset VCFs, following workflow from https://speciationgenomics.github.io/filtering_vcfs/
```bash
# Start new interactive environment if necessary
interactive -A naiss2023-5-262 -n 1 -t 1:00:00
module load bioinfo-tools
module load vcftools/0.1.16
```
### Stats for sparrow_biallelics_subset.vcf.gz
```bash
# Create a subdirectory called VCFtools
mkdir VCFtools

# Set environmental variables
SUBSET_VCF=/proj/sparrowhybridization/Pitaliae/working/Arianna/07_PreFiltering/sparrow_biallelics_subset.vcf.gz
OUT=/proj/sparrowhybridization/Pitaliae/working/Arianna/07_PreFiltering/VCFtools/sparrow_biallelics_subset

# Calculate allele frequency for each variant
# don't need to specify --max-alleles 2 as we've already filtered to just have biallelic
vcftools --gzvcf $SUBSET_VCF --freq2 --out $OUT  # sparrow_biallelics_subset.frq

# Calculate the mean depth of coverage per individual
vcftools --gzvcf $SUBSET_VCF --depth --out $OUT # sparrow_biallelics_subset.idepth

# Estimate the mean depth of coverage for each site
vcftools --gzvcf $SUBSET_VCF --site-mean-depth --out $OUT # sparrow_biallelics_subset.ldepth.mean

# Extract the site quality score for each site
vcftools --gzvcf $SUBSET_VCF --site-quality --out $OUT # sparrow_biallelics_subset.lqual

# Calculate proportion of missing data per sample/individual
vcftools --gzvcf $SUBSET_VCF --missing-indv --out $OUT # sparrow_biallelics_subset.imiss

# Calculate proportion of missing data per site
vcftools --gzvcf $SUBSET_VCF --missing-site --out $OUT # sparrow_biallelics_subset.lmiss

# Calculate heterozygosity and inbreeding coefficient per individual! Note: individuals are from different pops -> "the expected heterozygosity will be overestimated due to the Wahlund-effect" (source: https://speciationgenomics.github.io/filtering_vcfs/)
vcftools --gzvcf $SUBSET_VCF --het --out $OUT # sparrow_biallelics_subset.het

### Repeat steps from setting environmental variables onward for: sparrow_biallelics_subset_AUTOSOMES.vcf.gz, sparrow_biallelics_subset_SEX.vcf.gz, sparrow_biallelics_subset_zChrom.vcf.gz, sparrow_biallelics_subset_wChrom.vcf.gz
```
Outputs: 35 output files named [inputFilePrefix].[calculationType] located in the VCFtools subdirectory

## Move to R on local computer to visual stat we generated, following workflow from https://speciationgenomics.github.io/filtering_vcfs/

```bash
# Within project directory of local computer, create a directory to store the stats we just generate
mkdir VCF_filteringThreshold_stats
cd VCF_filteringThreshold_stats

# Copy VCFtools directory from server to local
scp -r arianna2@rackham.uppmax.uu.se:/proj/sparrowhybridization/Pitaliae/working/Arianna/07_PreFiltering/VCFtools .

# Create an R script within the VCF_filteringThreshold_stats directory called vcfStats.R
```

### Pull subsets again for sex chromosomes, try for a more representative sample to double check, following workflow from https://speciationgenomics.github.io/filtering_vcfs/
```bash
# Move to scripts directory
cd /proj/sparrowhybridization/Pitaliae/working/Arianna/Scripts/07_PreFiltering_scripts

# Create jobs to re-run subsetting for Z and W, mainly to get a larger subset for W
# 570,763 biallelic sites for W, pull ~ 80,000 for subset
# 3,398,265 biallelic sites for Z, pull ~ 80,000 for subset

# batch job 46476787
sbatch -A naiss2023-5-262 -p core -n 1 -t 5:00:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/07_PreFiltering -e ../Job_logs/07_PreFiltering_logs/subsetRedoW.err -J subsetRedoW --mail-user=ar4666al-s@student.lu.se --mail-type=ALL pullSubsets_redoW.sh

# batch job 46476823
sbatch -A naiss2023-5-262 -p core -n 1 -t 5:00:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/07_PreFiltering -e ../Job_logs/07_PreFiltering_logs/subsetRedoZ.err -J subsetRedoZ --mail-user=ar4666al-s@student.lu.se --mail-type=ALL pullSubsets_redoZ.sh

# Start an interactive session
interactive -A naiss2023-5-262 -n 1 -t 1:00:00
module load bioinfo-tools
module load vcftools/0.1.16

# Compress the new vcf subsets
bcftools view ./Subsets/126sample_CM071456.1_biallelicSites_subset_REDO.vcf -Oz -o sparrow_biallelics_subset_zChrom_REDO.vcf.gz
bcftools view ./Subsets/126sample_CM071464.1_biallelicSites_subset_REDO.vcf -Oz -o sparrow_biallelics_subset_wChrom_REDO.vcf.gz

# index the compressed VCFs
bcftools index sparrow_biallelics_subset_zChrom_REDO.vcf.gz
bcftools index sparrow_biallelics_subset_wChrom_REDO.vcf.gz

## Rerun stats on these new subsets. Repeat steps from setting environmental variables onward for: sparrow_biallelics_subset_zChrom_REDO.vcf.gz, sparrow_biallelics_subset_wChrom_REDO.vcf.gz

```
## Check for duplicate positions before filtering
```bash
# Move to 07_PreFiltering_scripts
cd /proj/sparrowhybridization/Pitaliae/working/Arianna/Scripts/07_PreFiltering_scripts

# Create a script which checks for duplicate positions called checkDups.sh

# Check for duplicates, batch job 46476877
sbatch -A naiss2023-5-262 --array=1-334 --ntasks=1 -t 2:00:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/07_PreFiltering -e ../Job_logs/07_PreFiltering_logs/checkDups.err -J checkdups --mail-user=ar4666al-s@student.lu.se --mail-type=ALL checkDups.sh

# Move to 07_PreFiltering
cd /proj/sparrowhybridization/Pitaliae/working/Arianna/07_PreFiltering

# Open the output file which shows if duplicates exist
cat bcf_contains_dups_list # no duplicates!
```

# Filter
```bash
cd /proj/sparrowhybridization/Pitaliae/working/Arianna
mkdir 08_Filtering
cd 08_Filtering

# Pull paths to biallelic bcfs - AUTOSOMES & Z only, won't look at W for now (very minimal female samples, very low depth)!!
for bcf in ../06_BiallelicSiteBCFs/*bcf; do

    prefix=$(basename "$bcf" .bcf)

    if [[ "$prefix" == *CM071464.1* ]]; # if W chrom (CM071464.1)
    then
        continue # don't do anything
    else
        echo ${bcf} >> biallelic_bcf_paths_autosomesZ # append path to autosomal & Z bcf to the list
    fi
done

# Create two different sub-directories to store vcfs with different filtering parameters
mkdir InclMaxMissing
mkdir SansMaxMissing

# Move to the scripts directory
cd Scripts
mkdir 08_Filtering_scripts

# Create two scripts for filtering! One which contains a filter for the --max-missingess parameter (filterBiallelic_autosomesZ_inclMaxMiss.sh) and one that doesn't (filterBiallelic_autosomesZ_sansMaxMiss.sh)

# Includes max-missingness parameter, submitted batch job 46594888
sbatch -A naiss2023-5-262 --array=1-333 --ntasks=20 -t 6:00:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/08_Filtering/InclMaxMissing -e ../../Job_logs/08_Filtering_logs/InclMaxMissing/filtering_autosomesZ_%a.err -o ../../Job_logs/08_Filtering_logs/InclMaxMissing/filtering_autosomesZ_%a.out -J filtering_autosomesZ_inclMaxMiss --mail-user=ar4666al-s@student.lu.se --mail-type=ALL filterBiallelic_autosomesZ_inclMaxMiss.sh

# Includes max-missingness parameter, submitted batch job 46611874
sbatch -A naiss2023-5-262 --array=1-333 --ntasks=20 -t 5:00:00 -D /proj/sparrowhybridization/Pitaliae/working/Arianna/08_Filtering/SansMaxMissing -e ../../Job_logs/08_Filtering_logs/SansMaxMissing/filtering_autosomesZ_%a.err -o ../../Job_logs/08_Filtering_logs/SansMaxMissing/filtering_autosomesZ_%a.out -J filtering_autosomesZ_sansMaxMiss --mail-user=ar4666al-s@student.lu.se --mail-type=ALL filterBiallelic_autosomesZ_sansMaxMiss.sh
```
Outputs: 334 compressed VCF files in each subdirectory (InclMaxMissing and SansMaxMissing) of 08_Filtering. Files are named 126sample_[regionID]_biallelicSites_filtered.vcf.gz

## Concatenate the scaffold VCFs
```bash
# Request an interactive environment
interactive -A naiss2023-5-262 -n 20 -t 1:00:00
module load bioinfo-tools
module load bcftools/1.14

# Move to filtering directory if not there already
cd /proj/sparrowhybridization/Pitaliae/working/Arianna/08_Filtering

# First, work on the filtered VCFs in the InclMaxMissing directory
cd InclMaxMissing

# Make a subdirectory to store filtered scaffolds
mkdir AllScaffolds_biallelicSites

# Move all the scaffolds into that subdriectory
for vcf_gz in ./*_biallelicSites_filtered.vcf.gz; do # ${vcf} contains entire path

    prefix=$(basename "$vcf_gz" .vcf.gz)

    if [[ "$prefix" == *JAZGKA010000010.1* || "$prefix" == *JAZGKA010000030.1* || "$prefix" == *CM0714* ]]; # chromosomes (CM0714), SUPER_8 (JAZGKA010000010.1), SUPER_26 (JAZGKA010000030.1)
    then
        continue
    else
       mv ${vcf_gz} AllScaffolds_biallelicSites
    fi
done

# Concatenate the scaffolds, the output will be located in the InclMaxMissing directory!
bcftools concat --threads 20 126sample_AllScaffolds_biallelicSites/*vcf.gz -Oz -o 126sample_scaffolds_biallelicSites_filtered.vcf.gz

# Archive and compress the entire directory containing filtered scaffolds
tar -cvzf AllScaffolds_biallelicSites.tar.gz AllScaffolds_biallelicSites
rm -r AllScaffolds_biallelicSites # remove the non-archived/non-compressed version of the directory

# Follow the same steps as above for the files in the SansMaxMissing directory
```
Outputs: 1 compressed VCF file in each subdirectory (InclMaxMissing and SansMaxMissing) of 08_Filtering called 126sample_scaffolds_biallelicSites_filtered.vcf.gz. 1 archived and compressed directory in each subdirectory (InclMaxMissing and SansMaxMissing) of 08_Filtering called AllScaffolds_biallelicSites.tar.gz